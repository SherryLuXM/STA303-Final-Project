---
title: "2022 Customer and Product Report"
subtitle: "Subtitle that indicates findings"
author: "Report prepared for MINGAR by Data Analytics Inc."
date: 2022-04-07
lang: "en"
output:
  pdf_document:
    template: report.tex
    toc: true
    toc_depth: 2
titlepage: true
titlepage-color: "6C3082"
titlepage-text-color: "FFFFFF"
titlepage-rule-color: "FFFFFF"
titlepage-rule-height: 2
---

```{r setup, message=FALSE}
library(tidyverse)
library(polite)
library(rvest)
library(haven)
library(cancensus)
```
\newpage

# Executive Summary

_Guidelines for the executive summary:_

* _No more than two pages_
* _Language is appropriate for a non-technical audience_
* _Bullet points are used where appropriate_
*	_A small number of key visualizations and/or tables are included_
*	_All research questions are addressed_

\newpage
# Technical report
_This part of the report is much more comprehensive than the executive summary. The audience is statistics/data-minded people, but you should NOT include code or unformatted R output here._


## Introduction

_Provide a brief introduction to your report and outline what the report will cover. This section is valuable for setting scope and expectations. _

### Research questions
* What are the characteristics of the new customers using the "Active" and "Advanced" line?
* How do the new customers differ from the traditional customers?
* Do the customers using the "Active" and "Advanced" line come from a different income base compared to the traditional customers?
* Do the devices' sleep tracking feature perform worse for users with darker skin?

## Informative title for section addressing a research question

_For each research question, you will want to briefly describe any data manipulation, show some exploratory plots/summary tables, report on any methods you use (i.e. models you fit) and the conclusions you draw from these_

```{r}
# This chunk provides an example of some things you can do with RMarkdown 

# read in the data (this will only work once you've set up the data!)
device_data <- read_csv("data-raw/device.Rds")

# create a visualization
device_data %>% 
  ggplot(aes(x = ))

```

## Informative title for section addressing a research question


## Discussion

_In this section you will summarize your findings across all the research questions and discuss the strengths and limitations of your work. It doesn't have to be long, but keep in mind that often people will just skim the intro and the discussion of a document like this, so make sure it is useful as a semi-standalone section (doesn't have to be completely standalone like the executive summary)._

### Strengths and limitations

\newpage
# Consultant information
## Consultant profiles

*Complete this section with a brief bio for each member of your group. If you are completing the project individually, you only need to complete one for yourself. In that case, change the title of this section to 'Consultant profile' instead. Examples below. This section is only marked for completeness, clarity and professionalism, not 'truth' so you can write it as if we're a few years in the future. Put your current degree in as completed and/or add your first choice grad school program, whatever you like. What skills related skills would you most like to highlight? What job title do you want?*

**Sherry Xiaoman Lu**. Sherry is a Data Scientist at Data Analytics. She specializes in statistical modeling, project management, and business leadership. Sherry earned her Bachelor of Science, Specialist in Mathematics and its applications, with a focus in Probability and Statistics from the University of Toronto in 2023.

**Rumteen Taheri Dolatabadi**. Rumteen is a Data Scientist in the technology sector with experience as an Actuary. He specializes in theoretical and mathematical probability. Rumteen earned his Bachelor of Science with a specializiation in Applied Mathematics and a concentration in Statistics and Probability from the University of Toronto in 2022. 

**Statsy McStatsstats**. Statsy is a senior consultant with Eminence Analytics. She specializes in data visualization. Statsy earned her Bachelor of Science, Specialist in Statistics Methods and Practice, from the University of Toronto in 2023.

**Datana Scatterplot**. Datana is a junior consultant with Eminence Analytics. They specialize in reproducible analysis and statistical communication. Datana earned their Bachelor of Science, Majoring in Computer Science and Statistics from the University of Toronto in 2024.

## Code of ethical conduct

_This section should be fairly short, no more than half a page. Assume a general audience, much like your executive summary._

* _Make at least three relevant statements about your company's approach to ethical statistical consulting. These should be appropriately in line with professional conduct advice like the (Statistical Society of Canada Code of Conduct)[https://ssc.ca/sites/default/files/data/Members/public/Accreditation/ethics_e.pdf] or the (Ethical Guidelines for Statistical Practice from the American Statistical Society)[https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx]. For example, "the customer is always right" ISN'T the type of thing an ethical statistical consultant would include._
*	_Be very careful not to just copy and paste from these other documents! Put things in your own words._


\newpage
# References

_You don't need to cite course materials, but consider all the the places you got data from, as well as the packages used and R itself. These are all things you should consider citing. Likewise, you might use some external resources on the emoji skin tones/Fitzpatrick scale, etc._

\newpage
# Appendix

_These appendices should outline in more detail the steps taken to access the following datasets. They should NOT include code, but should briefly describe the steps and important considerations. I.e., show that you understand what needs to be considered when web scraping, protecting licensed data, etc._

## Web scraping industry data on fitness tracker devices
```{r}
# webscraping
url <- "https://fitnesstrackerinfohub.netlify.app"

target <- bow(url,
              user_agent = "sherryxiaoman.lu@mail.utoronto.ca for STA303/1002 final project",
              force = TRUE)
target

html <- scrape(target)

device_data <- html %>% 
  html_elements("table") %>% 
  html_table() %>% 
  pluck(1)

saveRDS(device_data, file = "data-raw/device_data.Rds")
```

## Accessing Census data on median household income
```{r}
options(cancensus.api_key = "CensusMapper_c35605992b233a54f504b09dcd8d5687",
        cancensus.cache_path = "cache")

regions <- list_census_regions(dataset = "CA16")

regions_filtered <-  regions %>% 
  filter(level == "CSD") %>% # CSD are Census Subdivision; it is a geographic level
  as_census_region_list()

census_data_csd <- get_census(dataset='CA16', regions = regions_filtered,
                          vectors=c("v_CA16_2397"),
                          level='CSD', geo_format = "sf")

median_income <- census_data_csd %>% 
  as_tibble() %>% 
  select(CSDuid = GeoUID, contains("median"), Population) %>% 
  mutate(CSDuid = parse_number(CSDuid)) %>% 
  rename(hhld_median_inc = 2)

saveRDS(median_income, file = "data-raw/median_income.Rds")
```

## Accessing postcode conversion files
```{r}
# load postal code data
postcode = read_sav("data-raw/pccfNat_fccpNat_082021sav.sav", col_select = c(PC, CSDuid))
view(postcode)
# postcode has duplicating rows
postcode = unique(postcode) # delete duplicating rows
saveRDS(postcode, file = "data-raw/postcode.Rds")
```

## Process data for racial data modeling
```{r}
cust_sleep = readRDS("data-raw/cust_sleep.Rds")
fullRds = readRDS("data-raw/full.Rds")
full = inner_join(cust_sleep, fullRds)

#glimpse(cust_sleep)
#glimpse(fullRds)
#glimpse(full)

full <- full[!is.na(full$emoji_modifier),]
full <- full %>%
  mutate (skin_tone =  case_when(emoji_modifier == "U+1F3FB" ~ "light",
                                 emoji_modifier == "U+1F3FC" ~ "medium-light",
                                 emoji_modifier == "U+1F3FD" ~ "medium",
                                 emoji_modifier == "U+1F3FE" ~ "medium-dark",
                                 emoji_modifier == "U+1F3FF" ~ "dark",))
full$skin_tone <- ordered(full$skin_tone, levels = c('light', 'medium-light', 'medium', 'medium-dark', 'dark'))
full <- mutate(full, freq = flags/duration*60)


racial_data <- select(full, cust_id, skin_tone, duration, flags)
#glimpse(racial_data)
saveRDS(racial_data, file = "data/racial_data.Rds")
```
## Assumptions Check
1.Poisson Response The response variable is a count per unit of time or space, described by a Poisson distribution.
2.Independence The observations must be independent of one another.
3.Mean=Variance By definition, the mean of a Poisson random variable must be equal to its variance.
4.Linearity The log of the mean rate, log(Î»), must be a linear function of x

## Exploratory Data Analysis
```{r}
mean(full$flags)
var(full$flags)

prop.table(table(full$skin_tone))

full  %>% group_by(skin_tone)  %>% 
  summarise(mean=mean(flags), sd=sd(flags), 
            var=var(flags), n=n())


mean(full$freq)
var(full$freq)
full  %>% group_by(skin_tone)  %>% 
  summarise(mean=mean(freq), 
            var=var(freq), n=n()) %>% 
knitr::kable(
      caption="Compare mean and variance of flag frequency within each skin color group.",
      col.names = c("Skin Tone", "Mean", "Variance", "n"))

```
The table shows that the variance of flags is bigger than the mean for all skin tone groups, with increasing discrepancy as the skin tone darkens. It is an violation of the third assumption for Poisson distribution.
For <freq>, the variance is always smaller than the mean.
```{r}
sumStats <- full %>% group_by(skin_tone) %>% 
  summarise(mnfreq = mean(freq),
            logmnfreq = log(mnfreq), n=n())
ggplot(sumStats, aes(x=skin_tone, y=logmnfreq)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1.5)+
  xlab("Customer Skin Tone") +
  ylab("Log of the empirical mean frequency of flags") +
  theme_minimal()
```
It shows a linear relationship between skin tone and log of frequency, so assumption 4 for the Poisson model is validated.
```{r}

```

```{r}

```

## Racial data modeling
```{r}
#Fit the GLMM
racial_data <- readRDS("data/racial_data.Rds")

model1 <- glmer(flags~skin_tone+(1|cust_id), family=poisson(link = log), offset = log(duration), data=racial_data)


summary(model1)
#exp(confint(model1))

ggplot(na.omit(full), aes(x=skin_tone, fill = sex)) +
geom_bar()
```

```{r}
confint(model1)
exp(confint(model1))
```

## null model and chi-square test
```{r}


```
# show interaction term is not needed
```{r}


```
# show additional terms are not needed

# residual plots

# goodness-of-fit test
```{r}


```

